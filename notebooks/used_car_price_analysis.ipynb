{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9e4330",
   "metadata": {},
   "source": [
    "# Used Car Price Analysis\n",
    "UC Berkeley – Professional Certificate in Machine Learning & AI  \n",
    "Practical Application 11.1 – *What Determines the Price of a Car?*\n",
    "\n",
    "This notebook follows the **CRISP-DM** framework:\n",
    "\n",
    "1. Business Understanding  \n",
    "2. Data Understanding  \n",
    "3. Data Preparation  \n",
    "4. Modeling  \n",
    "5. Evaluation & Recommendations\n",
    "\n",
    "The goal is to understand which factors drive the price of a used car and to build a predictive model that can help used car dealers optimize their inventory and pricing strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Configure basic display options\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b1c31",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "Used car dealers need to know **what makes one used car more expensive than another**.  \n",
    "\n",
    "**Business question**\n",
    "\n",
    "> Which features of a used car (age, mileage, brand, condition, fuel type, etc.) are most strongly associated with its price?\n",
    "\n",
    "**Stakeholder**\n",
    "\n",
    "- A group of used car dealers interested in:\n",
    "  - Understanding what consumers value in a used car\n",
    "  - Prioritizing which cars to purchase for inventory\n",
    "  - Setting more accurate and data-driven prices\n",
    "\n",
    "We will answer this question using the dataset of used vehicles and standard regression techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Data Understanding\n",
    "\n",
    "# Adjust the path if needed so that it points to your vehicles.csv file\n",
    "data_path = \"vehicles.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape and basic information\n",
    "df.shape, df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric variables\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61803ad5",
   "metadata": {},
   "source": [
    "### 2.1 Target variable: price\n",
    "\n",
    "We start by looking at the distribution of the target variable (`price`). Prices are typically right-skewed, so later we may consider transformations (e.g., log-price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ed462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(df['price'].dropna(), bins=50)\n",
    "plt.title(\"Distribution of Used Car Prices\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b402ee3",
   "metadata": {},
   "source": [
    "### 2.2 Relationship between price and key continuous variables\n",
    "\n",
    "We focus on **mileage** (`odometer`) and **year**, which are likely to be strong drivers of price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4dd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price vs mileage\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(df['odometer'], df['price'], alpha=0.1)\n",
    "plt.title(\"Price vs. Mileage (Odometer)\")\n",
    "plt.xlabel(\"Odometer\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "# Price vs year\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(df['year'], df['price'], alpha=0.1)\n",
    "plt.title(\"Price vs. Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86670744",
   "metadata": {},
   "source": [
    "### 2.3 Price by categorical features\n",
    "\n",
    "We also inspect how price varies across a few important categorical variables, such as **manufacturer** and **condition**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ad789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top manufacturers by count\n",
    "top_makes = df['manufacturer'].value_counts().head(10).index\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df[df['manufacturer'].isin(top_makes)],\n",
    "            x='manufacturer', y='price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Price Distribution by Manufacturer (Top 10)\")\n",
    "plt.xlabel(\"Manufacturer\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=df, x='condition', y='price')\n",
    "plt.title(\"Price Distribution by Condition\")\n",
    "plt.xlabel(\"Condition\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca57373",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "We now clean the data, engineer new features, and prepare the dataset for modeling.\n",
    "\n",
    "Steps:\n",
    "1. Remove missing or unrealistic prices  \n",
    "2. Create **age** from `year`  \n",
    "3. Filter to rows with key information (year, odometer, manufacturer, etc.)  \n",
    "4. Select a subset of relevant features  \n",
    "5. Encode categorical variables using one-hot encoding  \n",
    "6. Split into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4985c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Remove rows with missing or zero/negative price\n",
    "df_clean = df.dropna(subset=['price']).copy()\n",
    "df_clean = df_clean[df_clean['price'] > 0]\n",
    "\n",
    "# Remove extreme price outliers (simple rule-of-thumb thresholds)\n",
    "df_clean = df_clean[df_clean['price'].between(500, 100000)]\n",
    "\n",
    "# 3.2 Create age feature from year\n",
    "current_year = 2025\n",
    "df_clean = df_clean[df_clean['year'].notna()]\n",
    "df_clean['age'] = current_year - df_clean['year']\n",
    "\n",
    "# 3.3 Keep rows with non-missing key features\n",
    "key_cols = ['odometer', 'manufacturer', 'condition', 'fuel',\n",
    "            'transmission', 'type', 'state']\n",
    "df_clean = df_clean.dropna(subset=key_cols)\n",
    "\n",
    "# 3.4 Select modeling columns\n",
    "model_cols = ['price', 'age', 'odometer',\n",
    "              'manufacturer', 'condition', 'cylinders',\n",
    "              'fuel', 'transmission', 'type', 'state']\n",
    "\n",
    "df_model = df_clean[model_cols].copy()\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Encode categorical variables using one-hot encoding\n",
    "categorical_cols = ['manufacturer', 'condition', 'cylinders',\n",
    "                    'fuel', 'transmission', 'type', 'state']\n",
    "\n",
    "df_encoded = pd.get_dummies(df_model, columns=categorical_cols,\n",
    "                            drop_first=True)\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d59439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 Train-test split\n",
    "X = df_encoded.drop('price', axis=1)\n",
    "y = df_encoded['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8b748",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "\n",
    "We start with a **Multiple Linear Regression** model as a baseline.  \n",
    "Then we fit **Ridge** and **Lasso** regression with cross-validation and grid search over hyperparameters.\n",
    "\n",
    "We will evaluate performance mainly with **Root Mean Squared Error (RMSE)**, which penalizes large errors and is commonly used for regression tasks where large mispricing can be costly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Baseline: Multiple Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lin_reg.predict(X_test)\n",
    "\n",
    "rmse_lr = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Linear Regression RMSE: {rmse_lr:,.2f}\")\n",
    "print(f\"Linear Regression MAE : {mae_lr:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Cross-validation for the linear regression model\n",
    "cv_scores = cross_val_score(\n",
    "    lin_reg, X_train, y_train,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5\n",
    ")\n",
    "rmse_cv = -cv_scores\n",
    "print(\"Cross-validated RMSE (mean ± std): \"\n",
    "      f\"{rmse_cv.mean():,.2f} ± {rmse_cv.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Ridge Regression with Grid Search\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_params = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "ridge_grid = GridSearchCV(\n",
    "    ridge,\n",
    "    ridge_params,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Ridge params:\", ridge_grid.best_params_)\n",
    "print(\"Best Ridge CV RMSE:\", -ridge_grid.best_score_)\n",
    "\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "y_pred_ridge = best_ridge.predict(X_test)\n",
    "\n",
    "rmse_ridge = mean_squared_error(y_test, y_pred_ridge, squared=False)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"Ridge Test RMSE: {rmse_ridge:,.2f}\")\n",
    "print(f\"Ridge Test MAE : {mae_ridge:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Lasso Regression with Grid Search\n",
    "lasso = Lasso(max_iter=10000)\n",
    "\n",
    "lasso_params = {'alpha': [0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "lasso_grid = GridSearchCV(\n",
    "    lasso,\n",
    "    lasso_params,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Lasso params:\", lasso_grid.best_params_)\n",
    "print(\"Best Lasso CV RMSE:\", -lasso_grid.best_score_)\n",
    "\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "y_pred_lasso = best_lasso.predict(X_test)\n",
    "\n",
    "rmse_lasso = mean_squared_error(y_test, y_pred_lasso, squared=False)\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"Lasso Test RMSE: {rmse_lasso:,.2f}\")\n",
    "print(f\"Lasso Test MAE : {mae_lasso:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a851de1",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "We now compare the performance of the three models (Linear, Ridge, Lasso) and interpret the coefficients of the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d90c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'model': ['Linear Regression', 'Ridge Regression', 'Lasso Regression'],\n",
    "    'RMSE': [rmse_lr, rmse_ridge, rmse_lasso],\n",
    "    'MAE': [mae_lr, mae_ridge, mae_lasso]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98614559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model with the lowest RMSE for interpretation.\n",
    "# Here we assume Ridge performs best; adjust if your results differ.\n",
    "best_model = best_ridge\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': best_model.coef_\n",
    "}).sort_values(by='coefficient', ascending=False)\n",
    "\n",
    "coef_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9fb39",
   "metadata": {},
   "source": [
    "## 6. Business Interpretation & Recommendations\n",
    "\n",
    "Based on the model:\n",
    "\n",
    "- **Age** and **mileage** (odometer) typically have **negative coefficients**, indicating that older and higher-mileage cars sell for lower prices, all else equal.\n",
    "- Certain **manufacturers** show positive coefficients, suggesting that these brands retain value better than others.\n",
    "- Features such as **fuel type**, **transmission** (e.g., automatic), or **vehicle type** (e.g., SUV vs. sedan) may also contribute positively or negatively to price.\n",
    "\n",
    "### Non-technical summary for used car dealers\n",
    "\n",
    "1. **Prioritize newer, low-mileage vehicles.**  \n",
    "   These vehicles command higher prices and are less likely to be discounted heavily.\n",
    "\n",
    "2. **Focus on brands that retain value.**  \n",
    "   Brands with consistently positive coefficients are good candidates for inventory expansion.\n",
    "\n",
    "3. **Transmission and fuel type matter.**  \n",
    "   In many markets, automatic transmission and hybrid/electric vehicles may attract higher willingness to pay.\n",
    "\n",
    "4. **Use the model as a pricing assistant.**  \n",
    "   The predicted price can be used as a reference when purchasing vehicles at auctions or setting retail prices.\n",
    "\n",
    "### Next steps\n",
    "\n",
    "- Explore non-linear models (e.g., tree-based ensembles) to capture more complex interactions.\n",
    "- Segment the analysis by region or body type to refine pricing strategy.\n",
    "- Deploy this model as part of a simple pricing dashboard for sales staff.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
